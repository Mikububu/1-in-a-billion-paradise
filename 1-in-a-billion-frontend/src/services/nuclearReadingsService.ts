/**
 * NUCLEAR READINGS SERVICE
 * 
 * Fetches nuclear_v2 readings from Supabase job queue.
 * These are the 16-document packages generated by the backend.
 */

import { supabase, isSupabaseConfigured } from './supabase';
import { env } from '@/config/env';
import axios from 'axios';

// Types
export type JobStatus = 'pending' | 'processing' | 'complete' | 'error';

export type NuclearJob = {
  id: string;
  user_id: string;
  type: 'nuclear_v2';
  status: JobStatus;
  input: {
    person1: { name: string };
    person2: { name: string };
    systems: string[];
  };
  progress: {
    totalTasks: number;
    completedTasks: number;
  };
  created_at: string;
  updated_at: string;
};

export type JobArtifact = {
  id: string;
  job_id: string;
  task_id: string;
  artifact_type: 'text' | 'audio' | 'pdf' | 'audio_mp3' | 'audio_m4a' | 'audio_song';
  storage_path: string;
  storage_url?: string;
  metadata?: {
    title?: string;
    docNum?: number;
    system?: string;
    wordCount?: number;
    kind?: string; // e.g. "combined" for audiobook, if set by backend
    lyrics?: string; // For song artifacts
    duration?: number; // For song artifacts
    style?: string; // For song artifacts
  };
  created_at: string;
};

export type NuclearReading = {
  job: NuclearJob;
  artifacts: JobArtifact[];
  texts: { [taskId: string]: string }; // Loaded text content
};

// Fetch all nuclear jobs for current user
export const fetchNuclearJobs = async (): Promise<NuclearJob[]> => {
  if (!isSupabaseConfigured) {
    console.warn('Supabase not configured');
    return [];
  }

  try {
    const { data: { user } } = await supabase.auth.getUser();
    if (!user) {
      console.warn('No authenticated user');
      return [];
    }

    const { data, error } = await supabase
      .from('jobs')
      .select('*')
      .eq('user_id', user.id)
      .eq('type', 'nuclear_v2')
      .order('created_at', { ascending: false });

    if (error) {
      console.error('Error fetching nuclear jobs:', error);
      return [];
    }

    return data || [];
  } catch (err) {
    console.error('Error in fetchNuclearJobs:', err);
    return [];
  }
};

// Fetch artifacts for a job
export const fetchJobArtifacts = async (
  jobId: string,
  artifactTypes?: Array<JobArtifact['artifact_type']>
): Promise<JobArtifact[]> => {
  // METHOD 1: Try backend API first (bypasses RLS, includes signed URLs)
  try {
    const backendUrl = env.CORE_API_URL || process.env.EXPO_PUBLIC_CORE_API_URL;
    if (backendUrl) {
      // Get auth token for backend
      const { data: { session } } = await supabase.auth.getSession();
      const headers: Record<string, string> = {};
      if (session?.access_token) {
        headers['Authorization'] = `Bearer ${session.access_token}`;
      }

      const response = await axios.get(`${backendUrl}/api/jobs/v2/${jobId}`, { headers });
      
      if (response.data?.success && response.data?.job?.artifacts) {
        let artifacts = response.data.job.artifacts as JobArtifact[];
        
        // Filter by artifact types if specified
        if (Array.isArray(artifactTypes) && artifactTypes.length > 0) {
          artifacts = artifacts.filter(a => artifactTypes.includes(a.artifact_type));
        }
        
        if (__DEV__) {
          console.log(`✅ Fetched ${artifacts.length} artifacts via backend API for job ${jobId.substring(0, 8)}`);
        }
        
        return artifacts;
      }
    }
  } catch (backendError: any) {
    if (__DEV__) {
      console.warn('⚠️ Backend API failed, falling back to Supabase:', backendError.message);
    }
  }

  // METHOD 2: Fallback to direct Supabase query (requires RLS)
  if (!isSupabaseConfigured) {
    console.warn('⚠️ Supabase not configured');
    return [];
  }

  try {
    // CRITICAL: Ensure we have an active session before querying
    const { data: { session }, error: sessionError } = await supabase.auth.getSession();
    
    if (sessionError || !session) {
      console.warn('⚠️ No active session for artifact fetch:', sessionError?.message || 'No session');
      // Try to refresh session
      const { data: { user }, error: userError } = await supabase.auth.getUser();
      if (userError || !user) {
        console.warn('⚠️ No authenticated user for artifact fetch');
        return [];
      }
    }

    let q = supabase
      .from('job_artifacts')
      .select('*')
      .eq('job_id', jobId)
      .order('created_at', { ascending: true });

    if (Array.isArray(artifactTypes) && artifactTypes.length > 0) {
      q = q.in('artifact_type', artifactTypes);
    }

    const { data, error } = await q;

    if (error) {
      console.error('❌ Error fetching artifacts from Supabase:', {
        message: error.message,
        code: error.code,
        details: error.details,
        hint: error.hint,
        jobId: jobId.substring(0, 8),
        artifactTypes,
      });
      return [];
    }

    if (__DEV__) {
      console.log(`✅ Fetched ${data?.length || 0} artifacts from Supabase for job ${jobId.substring(0, 8)} (types: ${artifactTypes?.join(',') || 'all'})`);
    }

    return data || [];
  } catch (err: any) {
    console.error('❌ Exception in fetchJobArtifacts:', err.message);
    return [];
  }
};

export const createArtifactSignedUrl = async (storagePath: string, expiresInSeconds: number = 60 * 60) => {
  if (!isSupabaseConfigured) return null;
  try {
    const { data, error } = await supabase.storage
      .from('job-artifacts')
      .createSignedUrl(storagePath, expiresInSeconds);
    if (error) return null;
    return data?.signedUrl || null;
  } catch {
    return null;
  }
};

export type SoulJourneyChapter = {
  docNum: number;
  title: string;
  system?: string;
  textArtifact?: JobArtifact;
  audioArtifact?: JobArtifact;
  pdfArtifact?: JobArtifact;
};

export const buildSoulJourneyChapters = (artifacts: JobArtifact[]): SoulJourneyChapter[] => {
  // Group artifacts by docNum when available. If docNum missing, fall back to created_at order.
  const byDoc = new Map<number, SoulJourneyChapter>();
  const fallback: SoulJourneyChapter[] = [];

  const normalizeDocNum = (a: JobArtifact) => {
    const n = a?.metadata?.docNum;
    return typeof n === 'number' && Number.isFinite(n) ? n : null;
  };

  const upsert = (docNum: number, patch: Partial<SoulJourneyChapter>) => {
    const existing = byDoc.get(docNum) || {
      docNum,
      title: patch.title || `Chapter ${docNum}`,
      system: patch.system,
    };
    const next: SoulJourneyChapter = {
      ...existing,
      ...patch,
      title: patch.title || existing.title,
      system: patch.system || existing.system,
    };
    byDoc.set(docNum, next);
  };

  // Sort stable by created_at so fallbacks are deterministic
  const sorted = [...artifacts].sort((a, b) => (Date.parse(a.created_at) || 0) - (Date.parse(b.created_at) || 0));

  for (const a of sorted) {
    const docNum = normalizeDocNum(a);
    const title = a?.metadata?.title;
    const system = a?.metadata?.system;
    const isAudio = a.artifact_type === 'audio' || String(a.artifact_type).startsWith('audio_');

    if (docNum === null) {
      fallback.push({
        docNum: fallback.length + 1,
        title: title || `Chapter ${fallback.length + 1}`,
        system,
        ...(a.artifact_type === 'text' ? { textArtifact: a } : {}),
        ...(isAudio ? { audioArtifact: a } : {}),
        ...(a.artifact_type === 'pdf' ? { pdfArtifact: a } : {}),
      });
      continue;
    }

    if (a.artifact_type === 'text') upsert(docNum, { title: title || `Chapter ${docNum}`, system, textArtifact: a });
    if (isAudio) upsert(docNum, { title: title || `Chapter ${docNum}`, system, audioArtifact: a });
    if (a.artifact_type === 'pdf') upsert(docNum, { title: title || `Chapter ${docNum}`, system, pdfArtifact: a });
  }

  const chapters = [...byDoc.values()].sort((a, b) => a.docNum - b.docNum);
  return chapters.length > 0 ? chapters : fallback;
};

// Download text content from storage
export const downloadTextContent = async (storagePath: string): Promise<string | null> => {
  if (!isSupabaseConfigured) return null;

  try {
    const { data, error } = await supabase.storage
      .from('job-artifacts')
      .download(storagePath);

    if (error) {
      console.error('Error downloading text:', error);
      return null;
    }

    if (!data) {
      console.error('No data returned from download');
      return null;
    }

    // Convert Blob to text using FileReader (React Native compatible)
    return new Promise<string>((resolve, reject) => {
      const reader = new FileReader();
      reader.onloadend = () => {
        if (typeof reader.result === 'string') {
          resolve(reader.result);
        } else {
          reject(new Error('Failed to read text'));
        }
      };
      reader.onerror = reject;
      reader.readAsText(data);
    });
  } catch (err) {
    console.error('Error in downloadTextContent:', err);
    return null;
  }
};

// Fetch complete nuclear reading with all texts
export const fetchNuclearReading = async (jobId: string): Promise<NuclearReading | null> => {
  try {
    // Get job
    const { data: job, error: jobError } = await supabase
      .from('jobs')
      .select('*')
      .eq('id', jobId)
      .single();

    if (jobError || !job) {
      console.error('Error fetching job:', jobError);
      return null;
    }

    // Get artifacts (all types)
    const artifacts = await fetchJobArtifacts(jobId);

    // Download all text content
    const texts: { [taskId: string]: string } = {};
    for (const artifact of artifacts) {
      const content = await downloadTextContent(artifact.storage_path);
      if (content) {
        texts[artifact.task_id] = content;
      }
    }

    return { job, artifacts, texts };
  } catch (err) {
    console.error('Error in fetchNuclearReading:', err);
    return null;
  }
};

// Get summary of all nuclear readings (for library list)
export const getNuclearReadingsSummary = async () => {
  const jobs = await fetchNuclearJobs();
  
  return jobs.map(job => ({
    id: job.id,
    person1Name: job.input?.person1?.name || 'Person 1',
    person2Name: job.input?.person2?.name || 'Person 2',
    status: job.status,
    progress: job.progress,
    createdAt: job.created_at,
    isComplete: job.status === 'complete',
  }));
};

