/**
 * NUCLEAR READINGS SERVICE
 * 
 * Fetches nuclear_v2 readings from Supabase job queue.
 * These are the 16-document packages generated by the backend.
 */

import { supabase, isSupabaseConfigured } from './supabase';

// Types
export type JobStatus = 'pending' | 'processing' | 'complete' | 'error';

export type NuclearJob = {
  id: string;
  user_id: string;
  type: 'nuclear_v2';
  status: JobStatus;
  input: {
    person1: { name: string };
    person2: { name: string };
    systems: string[];
  };
  progress: {
    totalTasks: number;
    completedTasks: number;
  };
  created_at: string;
  updated_at: string;
};

export type JobArtifact = {
  id: string;
  job_id: string;
  task_id: string;
  artifact_type: 'text' | 'audio' | 'pdf' | 'audio_mp3' | 'audio_m4a' | 'audio_song';
  storage_path: string;
  storage_url?: string;
  metadata?: {
    title?: string;
    docNum?: number;
    system?: string;
    wordCount?: number;
    kind?: string;
    lyrics?: string;
    duration?: number;
    style?: string;
  };
  created_at: string;
};

export type NuclearReading = {
  job: NuclearJob;
  artifacts: JobArtifact[];
  texts: { [taskId: string]: string };
};

// Fetch all nuclear jobs for current user
export const fetchNuclearJobs = async (): Promise<NuclearJob[]> => {
  if (!isSupabaseConfigured) {
    console.warn('Supabase not configured');
    return [];
  }

  try {
    const { data: { user } } = await supabase.auth.getUser();
    if (!user) {
      console.warn('No authenticated user');
      return [];
    }

    const { data, error } = await supabase
      .from('jobs')
      .select('*')
      .eq('user_id', user.id)
      .eq('type', 'nuclear_v2')
      .order('created_at', { ascending: false });

    if (error) {
      console.error('Error fetching nuclear jobs:', error);
      return [];
    }

    return data || [];
  } catch (err) {
    console.error('Error in fetchNuclearJobs:', err);
    return [];
  }
};

// Fetch artifacts for a job (direct Supabase query)
export const fetchJobArtifacts = async (
  jobId: string,
  artifactTypes?: Array<JobArtifact['artifact_type']>
): Promise<JobArtifact[]> => {
  if (!isSupabaseConfigured) return [];

  try {
    let q = supabase
      .from('job_artifacts')
      .select('*')
      .eq('job_id', jobId)
      .order('created_at', { ascending: true });

    if (Array.isArray(artifactTypes) && artifactTypes.length > 0) {
      q = q.in('artifact_type', artifactTypes);
    }

    const { data, error } = await q;

    if (error) {
      if (__DEV__) {
        console.warn('Error fetching artifacts:', error.message);
      }
      return [];
    }

    return data || [];
  } catch (err) {
    console.error('Error in fetchJobArtifacts:', err);
    return [];
  }
};

export const createArtifactSignedUrl = async (storagePath: string, expiresInSeconds: number = 60 * 60) => {
  if (!isSupabaseConfigured) return null;
  try {
    const { data, error } = await supabase.storage
      .from('job-artifacts')
      .createSignedUrl(storagePath, expiresInSeconds);
    if (error) return null;
    return data?.signedUrl || null;
  } catch {
    return null;
  }
};

export type SoulJourneyChapter = {
  docNum: number;
  title: string;
  system?: string;
  textArtifact?: JobArtifact;
  audioArtifact?: JobArtifact;
  pdfArtifact?: JobArtifact;
};

export const buildSoulJourneyChapters = (artifacts: JobArtifact[]): SoulJourneyChapter[] => {
  const byDoc = new Map<number, SoulJourneyChapter>();
  const fallback: SoulJourneyChapter[] = [];

  const normalizeDocNum = (a: JobArtifact) => {
    const n = a?.metadata?.docNum;
    return typeof n === 'number' && Number.isFinite(n) ? n : null;
  };

  const upsert = (docNum: number, patch: Partial<SoulJourneyChapter>) => {
    const existing = byDoc.get(docNum) || {
      docNum,
      title: patch.title || `Chapter ${docNum}`,
      system: patch.system,
    };
    const next: SoulJourneyChapter = {
      ...existing,
      ...patch,
      title: patch.title || existing.title,
      system: patch.system || existing.system,
    };
    byDoc.set(docNum, next);
  };

  const sorted = [...artifacts].sort((a, b) => (Date.parse(a.created_at) || 0) - (Date.parse(b.created_at) || 0));

  for (const a of sorted) {
    const docNum = normalizeDocNum(a);
    const title = a?.metadata?.title;
    const system = a?.metadata?.system;
    const isAudio = a.artifact_type === 'audio' || String(a.artifact_type).startsWith('audio_');

    if (docNum === null) {
      fallback.push({
        docNum: fallback.length + 1,
        title: title || `Chapter ${fallback.length + 1}`,
        system,
        ...(a.artifact_type === 'text' ? { textArtifact: a } : {}),
        ...(isAudio ? { audioArtifact: a } : {}),
        ...(a.artifact_type === 'pdf' ? { pdfArtifact: a } : {}),
      });
      continue;
    }

    if (a.artifact_type === 'text') upsert(docNum, { title: title || `Chapter ${docNum}`, system, textArtifact: a });
    if (isAudio) upsert(docNum, { title: title || `Chapter ${docNum}`, system, audioArtifact: a });
    if (a.artifact_type === 'pdf') upsert(docNum, { title: title || `Chapter ${docNum}`, system, pdfArtifact: a });
  }

  const chapters = [...byDoc.values()].sort((a, b) => a.docNum - b.docNum);
  return chapters.length > 0 ? chapters : fallback;
};

// Download text content from storage
export const downloadTextContent = async (storagePath: string): Promise<string | null> => {
  if (!isSupabaseConfigured) return null;

  try {
    const { data, error } = await supabase.storage
      .from('job-artifacts')
      .download(storagePath);

    if (error) {
      console.error('Error downloading text:', error);
      return null;
    }

    if (!data) {
      console.error('No data returned from download');
      return null;
    }

    return new Promise<string>((resolve, reject) => {
      const reader = new FileReader();
      reader.onloadend = () => {
        if (typeof reader.result === 'string') {
          resolve(reader.result);
        } else {
          reject(new Error('Failed to read text'));
        }
      };
      reader.onerror = reject;
      reader.readAsText(data);
    });
  } catch (err) {
    console.error('Error in downloadTextContent:', err);
    return null;
  }
};

// Fetch complete nuclear reading with all texts
export const fetchNuclearReading = async (jobId: string): Promise<NuclearReading | null> => {
  try {
    const { data: job, error: jobError } = await supabase
      .from('jobs')
      .select('*')
      .eq('id', jobId)
      .single();

    if (jobError || !job) {
      console.error('Error fetching job:', jobError);
      return null;
    }

    const artifacts = await fetchJobArtifacts(jobId);

    const texts: { [taskId: string]: string } = {};
    for (const artifact of artifacts) {
      const content = await downloadTextContent(artifact.storage_path);
      if (content) {
        texts[artifact.task_id] = content;
      }
    }

    return { job, artifacts, texts };
  } catch (err) {
    console.error('Error in fetchNuclearReading:', err);
    return null;
  }
};

// Get summary of all nuclear readings (for library list)
export const getNuclearReadingsSummary = async () => {
  const jobs = await fetchNuclearJobs();
  
  return jobs.map(job => ({
    id: job.id,
    person1Name: job.input?.person1?.name || 'Person 1',
    person2Name: job.input?.person2?.name || 'Person 2',
    status: job.status,
    progress: job.progress,
    createdAt: job.created_at,
    isComplete: job.status === 'complete',
  }));
};
